{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "from psycopg2 import connect\n",
    "import pandas.io.sql as pandasql\n",
    "from IPython.display import HTML\n",
    "from psycopg2.extras import execute_values\n",
    "import requests\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import json\n",
    "import click \n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read(str(Path.home().joinpath('db.cfg')))\n",
    "dbset = CONFIG['DBSETTINGS']\n",
    "con = connect(**dbset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating query_info_table\n",
    "def create_query_info_table(layer_name):\n",
    "    sql = 'CREATE TABLE gis_shared_streets.'+layer_name+'_query_info_table (like gis_shared_streets.query_info_structure)'\n",
    "    with con:\n",
    "            with con.cursor() as cur:\n",
    "                cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input table \n",
    "# All input table should only include streets, if a street is bi-directional then there should be one geometry for each direction. \n",
    "\n",
    "sql= '''create view gis_shared_streets.centreline_streets_only as (select geo_id, direction, dir_geom AS geom from gis_shared_streets.centreline_both_dir where FCODE_DESC IN ('Collector','Collector Ramp',\n",
    "                'Local','Major Arterial','Major Arterial Ramp','Minor Arterial',\n",
    "                'Minor Arterial Ramp','Pending') ORDER BY geo_id)'''\n",
    "with con:\n",
    "    with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_rows length:199\n",
      "0\n",
      "unmatched_rows length:15\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34524"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use matching function\n",
    "unmatched_here_snap = matching(10, 0.6, 25, None, 'natalie.routing_street_18_3', 'gis_shared_streets.here_matched_snap','gis_shared_streets.here_query_info_table_snap', 'link_dir',None, con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching function \n",
    "def matching(search_radius, length_tolerance, bearing_tolerance, previously_unmatched_id, input_table, output_table, query_info_table, primary_key1, primary_key2, con):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function processes the input table and inserts the sharedstreets API outputs to the output table. \n",
    "    It returns a list of the unmatched unique identifers from the input table.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    search_radius : int\n",
    "        Search radius in meters for snapping streets to SharedStreets references (1-100 meters)\n",
    "        \n",
    "    length_tolerance : float\n",
    "        Line length for potential matches specified as a percent of total line length (0-1)\n",
    "        \n",
    "    bearing_tolerance : int\n",
    "        Degrees tolerance to allow for directional street queries (0-360 degrees)\n",
    "        \n",
    "    previously_unmatched_id : list\n",
    "        List of IDs that were unmatched with previous calls to this function. \n",
    "        If this is the first time calling the function on a dataset, then the value should be None\n",
    "        \n",
    "    input_table : string\n",
    "        Name of table with geometry that you would like to match to shared streets \n",
    "        Things to note:\n",
    "            1) All input table should only include streets, if a street is bi-directional then there should be one geometry for each direction.\n",
    "            2) There must be a primary key of one or two columns\n",
    "            \n",
    "    output_table : string\n",
    "        Name of table that the matched rows will be inserted into\n",
    "        \n",
    "    query_info_table :string\n",
    "        Name of the table that records the general information each time we run the function. \n",
    "        This includes parameters used, query number, number of matched rows, as well as the total number of rows that we attempted to match.\n",
    "        This table should be created with the same column as gis_shared_streets.query_info_structure. \n",
    "        \n",
    "    primary_key1 : string\n",
    "        The primary key of the input table\n",
    "        \n",
    "    primary_key2 : string\n",
    "        The second primary key of the input table (e.g. if primary_key1 is not the unique identifier for the table) \n",
    "    \n",
    "    con : string\n",
    "        Database connection credentials \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    unmatched_rows : list\n",
    "        List of the unmatched unique identifers (primary_key1 or primary_key1 + primary_key2) from the input table\n",
    "    \n",
    "    \"\"\"\n",
    "    # get query_num from query info table (i.e. the serial value that was just inputted)\n",
    "    sql_get_query_num = \"SELECT GREATEST(query_num) AS query_num FROM {}\".format(query_info_table)\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql_get_query_num) \n",
    "            query_results = cur.fetchall()\n",
    "            if query_results == []:\n",
    "                query_num = 1\n",
    "            else:\n",
    "                query_num = query_results[0]['query_num']\n",
    "            \n",
    "            \n",
    "    # If everything got matched\n",
    "    if previously_unmatched_id == []:\n",
    "        return \"Everything is matched\"\n",
    "    \n",
    "    \n",
    "    # If this is the first time we run the function, then count will be the total number of row in the input table\n",
    "    if previously_unmatched_id is None:    \n",
    "        count_sql = \"SELECT COUNT(*) FROM {}\".format(input_table)\n",
    "            \n",
    "        with con:\n",
    "            with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(count_sql)\n",
    "                    count_results = cur.fetchall()\n",
    "                    count = count_results[0]['count']\n",
    "                    \n",
    "                    \n",
    "    # If this is not the first time we run the function, then count will be the total number of row in the returned unmatched list of unique identifiers                              \n",
    "    else: \n",
    "        count = len(previously_unmatched_id)\n",
    "            \n",
    "    \n",
    "          \n",
    "    # list for all the ids that do not get matched \n",
    "    unmatched_rows = []\n",
    "    null_matched = []\n",
    "    \n",
    "    # If there is more than one primary key\n",
    "    if primary_key2 is not None:\n",
    "        for i in range(0, count, 300):\n",
    "                  \n",
    "            \n",
    "            # first time calling function on input table         \n",
    "            if previously_unmatched_id is None: \n",
    "\n",
    "                # two rows make up the primary key of the table\n",
    "                get_centreline_sql =  '''SELECT 'Feature' as type,  json_build_object('{}', {}, '{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {}\n",
    "                ORDER BY {}, {}\n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, str(primary_key1), primary_key2, str(primary_key2), input_table, primary_key1, primary_key2, i)\n",
    "\n",
    "\n",
    "            # calling function again\n",
    "            else:\n",
    "\n",
    "                get_centreline_sql = '''SELECT 'Feature' as type,  json_build_object('{}', {}, '{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {} WHERE {}||{} IN {} \n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, primary_key1, primary_key2, primary_key2, input_table, str(primary_key1), str(primary_key2),tuple(previously_unmatched_id), i)\n",
    "\n",
    "            with con:\n",
    "                with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(get_centreline_sql)\n",
    "                    results = cur.fetchall()\n",
    "                    final_json = json.dumps({\"type\": \"FeatureCollection\",\n",
    "                                            \"features\": results})\n",
    "            # Send data to SharedStreets API    \n",
    "            base_url = \"https://api.sharedstreets.io/v0.1.0/match/geoms\"\n",
    "            apiKey = \"bdd23fa1-7ac5-4158-b354-22ec946bb575\"\n",
    "            params = {'ignoreDirection': 'false',\n",
    "                      'bearingTolerance' : bearing_tolerance,\n",
    "                      'searchRadius' : search_radius,\n",
    "                      'auth' : apiKey,\n",
    "                      'tileHierarchy': 6,\n",
    "                      'dataSource': 'osm/planet-181029',\n",
    "                      'lengthTolerance' : length_tolerance,\n",
    "                      'snapTopology': 'true', \n",
    "                      'snapToIntersections': 'true'\n",
    "                     }\n",
    "            headers= {\"Content-type\": \"application/json; charset=UTF-8\"}\n",
    "\n",
    "            r = requests.post(base_url, params = params, headers = headers, json = {\"type\": \"FeatureCollection\", \"features\": results})\n",
    "            returned_json = r.json()\n",
    "            if returned_json.get('unmatched') is not None:\n",
    "                unmatched = returned_json.get('unmatched').get('features')\n",
    "                for feature in unmatched:\n",
    "\n",
    "                        unmatched_id1 = feature['properties']['{}'.format(primary_key1)]\n",
    "                        unmatched_id2 = feature['properties']['{}'.format(primary_key2)]\n",
    "                        unmatched_rows.append(str(unmatched_id1) + unmatched_id2)\n",
    "                \n",
    "             # Send row to database\n",
    "            if returned_json.get('matched') is not None:\n",
    "                features = returned_json.get('matched').get('features')\n",
    "                rows = []\n",
    "                for feature in features:\n",
    "                        if  feature['properties']['section'][0] > feature['properties']['section'][1]:\n",
    "                            feature['properties']['section'][0] = 0\n",
    "                            feature['properties']['section'][1] = 0\n",
    "\n",
    "                        if  feature['properties']['referenceId'] is None:\n",
    "                            null_matched.append((str(feature['properties']['{}'.format(primary_key1)]))+feature['properties']['{}'.format(primary_key2)])\n",
    "                            continue\n",
    "\n",
    "                        row = (feature['properties']['referenceId'], \n",
    "                                   feature['properties']['fromIntersectionId'],\n",
    "                                   feature['properties']['toIntersectionId'],\n",
    "                                   feature['properties']['roadClass'], \n",
    "                                   feature['properties']['direction'],\n",
    "                                   feature['properties']['referenceLength'],\n",
    "                                   feature['properties']['side'], \n",
    "                                   feature['properties'].get('score', None),\n",
    "                                   '[' + str(feature['properties']['section'][0]) +', '+ str(feature['properties']['section'][1]) +')', \n",
    "                                   'SRID=4326;LineString('+','.join(' '.join(str(x) for x in tup) for tup in feature['geometry']['coordinates'])+')', \n",
    "                                   feature['properties']['originalFeature']['properties']['{}'.format(primary_key1)],\n",
    "                                   feature['properties']['originalFeature']['properties']['{}'.format(primary_key2)], \n",
    "                                   query_num)\n",
    "\n",
    "\n",
    "                        rows.append(row)\n",
    "\n",
    "\n",
    "                sql='INSERT INTO {} (reference_id, from_intersection, to_intersection, road_class, ss_direction, reference_length, side,score, section, geometry, {}, {}, query_num) VALUES %s'.format(output_table, primary_key1, primary_key2)\n",
    "\n",
    "\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        execute_values(cur, sql, rows) \n",
    "\n",
    "                print(i)\n",
    "                print(\"unmatched_rows length:\" + str(len(unmatched_rows)))\n",
    "                print(\"matched_rows length:\" +str(len(rows)))\n",
    "                \n",
    "    else:\n",
    "        for i in range(0, count, 300):\n",
    "        \n",
    "            # First time calling function on input table         \n",
    "            if previously_unmatched_id is None: \n",
    "\n",
    "                # two rows make up the primary key of the table\n",
    "                get_centreline_sql =  '''SELECT 'Feature' as type,  json_build_object('{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {}\n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, str(primary_key1), input_table, i)\n",
    "\n",
    "\n",
    "            # calling function again\n",
    "            else:\n",
    "\n",
    "                get_centreline_sql = '''SELECT 'Feature' as type,  json_build_object('{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {} WHERE {} IN {} \n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, primary_key1, input_table, str(primary_key1), tuple(previously_unmatched_id), i)\n",
    "\n",
    "            with con:\n",
    "                with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(get_centreline_sql)\n",
    "                    results = cur.fetchall()\n",
    "                    final_json = json.dumps({\"type\": \"FeatureCollection\",\n",
    "                                            \"features\": results})\n",
    "                    \n",
    "            # Send data to SharedStreets API    \n",
    "            base_url = \"https://api.sharedstreets.io/v0.1.0/match/geoms\"\n",
    "            apiKey = \"bdd23fa1-7ac5-4158-b354-22ec946bb575\"\n",
    "            params = {'ignoreDirection': 'false',\n",
    "                      'bearingTolerance' : bearing_tolerance,\n",
    "                      'searchRadius' : search_radius,\n",
    "                      'auth' : apiKey,\n",
    "                      'tileHierarchy': 6,\n",
    "                      'dataSource': 'osm/planet-181029',\n",
    "                      'lengthTolerance' : length_tolerance,\n",
    "                      'snapTopology': 'true', \n",
    "                      'snapToIntersections': 'true'\n",
    "                     }\n",
    "            headers= {\"Content-type\": \"application/json; charset=UTF-8\"}\n",
    "\n",
    "            r = requests.post(base_url, params = params, headers = headers, json = {\"type\": \"FeatureCollection\", \"features\": results})\n",
    "            returned_json = r.json()\n",
    "            if returned_json.get('unmatched') is not None:\n",
    "                unmatched = returned_json.get('unmatched').get('features')\n",
    "                for feature in unmatched:\n",
    "                        unmatched_id1 = feature['properties']['{}'.format(primary_key1)]\n",
    "                        unmatched_rows.append(str(unmatched_id1))\n",
    "            \n",
    "             # Send row to database\n",
    "            if returned_json.get('matched') is None:\n",
    "                test_json = json.loads(final_json)\n",
    "                \n",
    "                for feature in test_json['features']:\n",
    "                        unmatched_1 = feature['properties']['{}'.format(primary_key1)]\n",
    "                        unmatched_rows.append(str(unmatched_1))\n",
    "                    \n",
    "            if returned_json.get('matched') is not None:\n",
    "                features = returned_json.get('matched').get('features')\n",
    "                rows = []\n",
    "                for feature in features:\n",
    "                        if  feature['properties']['section'][0] > feature['properties']['section'][1]:\n",
    "                            feature['properties']['section'][0] = 0\n",
    "                            feature['properties']['section'][1] = 0\n",
    "\n",
    "                        if  feature['properties']['referenceId'] is None:\n",
    "                            null_matched.append(str(feature['properties']['{}'.format(primary_key1)]))\n",
    "                            continue\n",
    "\n",
    "                        row = (feature['properties']['referenceId'], \n",
    "                                   feature['properties']['fromIntersectionId'],\n",
    "                                   feature['properties']['toIntersectionId'],\n",
    "                                   feature['properties']['roadClass'], \n",
    "                                   feature['properties']['direction'],\n",
    "                                   feature['properties']['referenceLength'],\n",
    "                                   feature['properties']['side'], \n",
    "                                   feature['properties'].get('score', None),\n",
    "                                   '[' + str(feature['properties']['section'][0]) +', '+ str(feature['properties']['section'][1]) +')', \n",
    "                                   'SRID=4326;LineString('+','.join(' '.join(str(x) for x in tup) for tup in feature['geometry']['coordinates'])+')', \n",
    "                                   feature['properties']['originalFeature']['properties']['{}'.format(primary_key1)],\n",
    "                                   None)\n",
    "\n",
    "\n",
    "                        rows.append(row)\n",
    "\n",
    "\n",
    "\n",
    "                sql='INSERT INTO {} (reference_id, from_intersection, to_intersection, road_class, ss_direction, reference_length, side,score, section, geometry, {},  query_num) VALUES %s'.format(output_table,primary_key1)\n",
    "\n",
    "\n",
    "                with con:\n",
    "                    with con.cursor() as cur:\n",
    "                        execute_values(cur, sql, rows) \n",
    "                print(\"matched_rows length:\" +str(len(rows)))\n",
    "            \n",
    "            print(i)\n",
    "            print(\"unmatched_rows length:\" + str(len(unmatched_rows)))\n",
    "                \n",
    "    \n",
    "    # put info on query into appropriate table\n",
    "    sql_query_info = 'INSERT INTO {} (query_num, bearing_tolerance, search_radius, length_tolerance, snap_to_intersection, tilehierarchy, total_rows, matched_rows)  VALUES %s'.format(query_info_table)\n",
    "    query_list = [(query_num, bearing_tolerance, search_radius, length_tolerance, params['snapToIntersections'], params['tileHierarchy'], count,count-len(unmatched_rows))]\n",
    "   \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            execute_values(cur, sql_query_info, query_list) \n",
    "    \n",
    "    \n",
    "    # update the output table with the correct query number so we can link the output table to the query_num table \n",
    "    sql_update_with_query_num = 'UPDATE {} set query_num = {} WHERE query_num IS NULL'.format(output_table, query_num)\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql_update_with_query_num) \n",
    "\n",
    "    \n",
    "    print(null_matched)\n",
    "    return unmatched_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
