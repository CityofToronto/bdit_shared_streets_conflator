{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "from psycopg2 import connect\n",
    "import pandas.io.sql as pandasql\n",
    "from IPython.display import HTML\n",
    "from psycopg2.extras import execute_values\n",
    "import requests\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import json\n",
    "import click \n",
    "CONFIG = configparser.ConfigParser()\n",
    "CONFIG.read(str(Path.home().joinpath('db.cfg')))\n",
    "dbset = CONFIG['DBSETTINGS']\n",
    "con = connect(**dbset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating query_info_table\n",
    "def create_query_info_table(layer_name):\n",
    "    sql = 'CREATE TABLE gis_shared_streets.'+layer_name+'_query_info_table (like gis_shared_streets.query_info_structure)'\n",
    "    with con:\n",
    "            with con.cursor() as cur:\n",
    "                cur.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input table \n",
    "# All input table should only include streets, if a street is bi-directional then there should be one geometry for each direction. \n",
    "\n",
    "sql= '''create view gis_shared_streets.centreline_streets_only as (select geo_id, direction, dir_geom AS geom from gis_shared_streets.centreline_both_dir where FCODE_DESC IN ('Collector','Collector Ramp',\n",
    "                'Local','Major Arterial','Major Arterial Ramp','Minor Arterial',\n",
    "                'Minor Arterial Ramp','Pending') ORDER BY geo_id)'''\n",
    "with con:\n",
    "    with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matching function\n",
    "unmatched_1_bt = matching(60, 0.8, 25, None, 'bluetooth.segments', 'gis_shared_streets.bluetooth_matched','gis_shared_streets.bluetooth_query_info', 'analysis_id', None,  con)\n",
    "len(unmatched_1_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching function \n",
    "def matching(search_radius, length_tolerance, bearing_tolerance, previously_unmatched_id, input_table, output_table, query_info_table, primary_key1, primary_key2, con):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function processes the input table and inserts the sharedstreets API outputs to the output table. It returns a list of the unmatched unique identifers from the input table.\n",
    "    \n",
    "    Inputs: \n",
    "    \n",
    "    search_radius -> Search radius in meters for snapping streets to SharedStreets references (1-100 meters)\n",
    "    length_tolerance -> Line length for potential matches specified as a percent of total line length (0-1)\n",
    "    bearing_tolerance -> Degrees tolerance to allow for directional street queries (0-360 degrees)\n",
    "    previously_unmatched_id -> list of IDs that were unmatched with previous calls to this function. \n",
    "                               If this is the first time calling the function on a dataset, then the value should be None\n",
    "    input_table -> name of table with geometry that you would like to match to shared streets \n",
    "                   Things to note:\n",
    "                   1) All input table should only include streets, if a street is bi-directional then there should be one geometry for each direction.\n",
    "                   2) There must be a primary key of one or two columns\n",
    "    output_table -> name of table that the matched rows will be inserted into\n",
    "    query_info_table -> name of the table that records the general information each time we run the function. \n",
    "                        This includes parameters used, query number, number of matched rows, as well as the total number of rows that we attempted to match.\n",
    "                        This table should be created with the same column as gis_shared_streets.query_info_structure. \n",
    "    primary_key1 -> the primary key of the input table\n",
    "    primary_key2 -> the second primary key of the input table (e.g. if primary_key1 is not the unique identifier for the table) \n",
    "    con -> database connection credentials \n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    unmatched_rows -> list of the unmatched unique identifers (primary_key1 or primary_key1 + primary_key2) from the input table\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # If everything got matched\n",
    "    if previously_unmatched_id == []:\n",
    "        return \"Everything is matched\"\n",
    "    \n",
    "    \n",
    "    # If this is the first time we run the function, then count will be the total number of row in the input table\n",
    "    if previously_unmatched_id is None:    \n",
    "        count_sql = \"SELECT COUNT(*) FROM {}\".format(input_table)\n",
    "            \n",
    "        with con:\n",
    "            with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(count_sql)\n",
    "                    count_results = cur.fetchall()\n",
    "                    count = count_results[0]['count']\n",
    "                    \n",
    "    # If this is not the first time we run the function, then count will be the total number of row in the returned unmatched list of unique identifiers                              \n",
    "    else: \n",
    "        count = len(previously_unmatched_id)\n",
    "            \n",
    "    \n",
    "    # list for all the ids that do not get matched \n",
    "    unmatched_rows = []\n",
    "    \n",
    "    # If there is more than one primary key\n",
    "    if primary_key2 is not None:\n",
    "        for i in range(0, count, 300):\n",
    "        \n",
    "            # first time calling function on input table         \n",
    "            if previously_unmatched_id is None: \n",
    "\n",
    "                # two rows make up the primary key of the table\n",
    "                get_centreline_sql =  '''SELECT 'Feature' as type,  json_build_object('{}', {}, '{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {}\n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, str(primary_key1), primary_key2, str(primary_key2), input_table, i)\n",
    "\n",
    "\n",
    "            # calling function again\n",
    "            else:\n",
    "\n",
    "                get_centreline_sql = '''SELECT 'Feature' as type,  json_build_object('{}', {}, '{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {} WHERE {}||{} IN {} \n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, primary_key1, primary_key2, primary_key2, input_table, str(primary_key1), str(primary_key2),tuple(previously_unmatched_id), i)\n",
    "\n",
    "            with con:\n",
    "                with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(get_centreline_sql)\n",
    "                    results = cur.fetchall()\n",
    "                    final_json = json.dumps({\"type\": \"FeatureCollection\",\n",
    "                                            \"features\": results})\n",
    "            # Send data to SharedStreets API    \n",
    "            base_url = \"https://api.sharedstreets.io/v0.1.0/match/geoms\"\n",
    "            apiKey = \"bdd23fa1-7ac5-4158-b354-22ec946bb575\"\n",
    "            params = {'ignoreDirection': 'false',\n",
    "                      'bearingTolerance' : bearing_tolerance,\n",
    "                      'searchRadius' : search_radius,\n",
    "                      'auth' : apiKey,\n",
    "                      'tileHierarchy': 6,\n",
    "                      'dataSource': 'osm/planet-181029',\n",
    "                      'lengthTolerance' : length_tolerance,\n",
    "                      'snapTopology': 'true'\n",
    "                     }\n",
    "            headers= {\"Content-type\": \"application/json; charset=UTF-8\"}\n",
    "\n",
    "            r = requests.post(base_url, params = params, headers = headers, json = {\"type\": \"FeatureCollection\", \"features\": results})\n",
    "            returned_json = r.json()\n",
    "            unmatched = returned_json.get('unmatched').get('features')\n",
    "            for feature in unmatched:\n",
    "\n",
    "                    unmatched_id1 = feature['properties']['{}'.format(primary_key1)]\n",
    "                    unmatched_id2 = feature['properties']['{}'.format(primary_key2)]\n",
    "                    unmatched_rows.append(str(unmatched_id1) + unmatched_id2)\n",
    "                \n",
    "             # Send row to database\n",
    "            features = returned_json.get('matched').get('features')\n",
    "            rows = []\n",
    "            for feature in features:\n",
    "                    if  feature['properties']['section'][0] > feature['properties']['section'][1]:\n",
    "                        feature['properties']['section'][0] = 0\n",
    "                        feature['properties']['section'][1] = 0\n",
    "\n",
    "                    if  feature['properties']['referenceId'] is None:\n",
    "                        null_matched.append((str(feature['properties']['{}'.format(primary_key1)]))+feature['properties']['{}'.format(primary_key2)])\n",
    "                        continue\n",
    "\n",
    "                    row = (feature['properties']['referenceId'], \n",
    "                               feature['properties']['fromIntersectionId'],\n",
    "                               feature['properties']['toIntersectionId'],\n",
    "                               feature['properties']['roadClass'], \n",
    "                               feature['properties']['direction'],\n",
    "                               feature['properties']['referenceLength'],\n",
    "                               feature['properties']['side'], \n",
    "                               feature['properties'].get('score', None),\n",
    "                               '[' + str(feature['properties']['section'][0]) +', '+ str(feature['properties']['section'][1]) +')', \n",
    "                               'SRID=4326;LineString('+','.join(' '.join(str(x) for x in tup) for tup in feature['geometry']['coordinates'])+')', \n",
    "                               feature['properties']['originalFeature']['properties']['{}'.format(primary_key1)],\n",
    "                               feature['properties']['originalFeature']['properties']['{}'.format(primary_key2)], \n",
    "                               query_num)\n",
    "\n",
    "\n",
    "                    rows.append(row)\n",
    "\n",
    "\n",
    "\n",
    "                    sql='INSERT INTO {} (reference_id, from_intersection, to_intersection, road_class, direction, reference_length, side,score, section, geometry, {}, {}, query_num) VALUES %s'.format(output_table, primary_key1, primary_key2)\n",
    "\n",
    "\n",
    "                    with con:\n",
    "                        with con.cursor() as cur:\n",
    "                            execute_values(cur, \n",
    "                                       sql, \n",
    "                                       rows) \n",
    "            \n",
    "    else:\n",
    "        for i in range(0, count, 300):\n",
    "        \n",
    "            # First time calling function on input table         \n",
    "            if previously_unmatched_id is None: \n",
    "\n",
    "                # two rows make up the primary key of the table\n",
    "                get_centreline_sql =  '''SELECT 'Feature' as type,  json_build_object('{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {}\n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, str(primary_key1), input_table, i)\n",
    "\n",
    "\n",
    "            # calling function again\n",
    "            else:\n",
    "\n",
    "                get_centreline_sql = '''SELECT 'Feature' as type,  json_build_object('{}', {}) as properties, ST_AsGeoJson(geom)::json as geometry \n",
    "                FROM {} WHERE {} IN {} \n",
    "                LIMIT 300 OFFSET {}'''.format(primary_key1, primary_key1, input_table, str(primary_key1), tuple(previously_unmatched_id), i)\n",
    "\n",
    "            with con:\n",
    "                with con.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "                    cur.execute(get_centreline_sql)\n",
    "                    results = cur.fetchall()\n",
    "                    final_json = json.dumps({\"type\": \"FeatureCollection\",\n",
    "                                            \"features\": results})\n",
    "            # Send data to SharedStreets API    \n",
    "            base_url = \"https://api.sharedstreets.io/v0.1.0/match/geoms\"\n",
    "            apiKey = \"bdd23fa1-7ac5-4158-b354-22ec946bb575\"\n",
    "            params = {'ignoreDirection': 'false',\n",
    "                      'bearingTolerance' : bearing_tolerance,\n",
    "                      'searchRadius' : search_radius,\n",
    "                      'auth' : apiKey,\n",
    "                      'tileHierarchy': 6,\n",
    "                      'dataSource': 'osm/planet-181029',\n",
    "                      'lengthTolerance' : length_tolerance,\n",
    "                      'snapTopology': 'true'\n",
    "                     }\n",
    "            headers= {\"Content-type\": \"application/json; charset=UTF-8\"}\n",
    "\n",
    "            r = requests.post(base_url, params = params, headers = headers, json = {\"type\": \"FeatureCollection\", \"features\": results})\n",
    "            returned_json = r.json()\n",
    "            unmatched = returned_json.get('unmatched').get('features')\n",
    "            for feature in unmatched:\n",
    "\n",
    "                    unmatched_id1 = feature['properties']['{}'.format(primary_key1)]\n",
    "                    unmatched_rows.append(str(unmatched_id1))\n",
    "                \n",
    "             # Send row to database\n",
    "            features = returned_json.get('matched').get('features')\n",
    "            rows = []\n",
    "            for feature in features:\n",
    "                    if  feature['properties']['section'][0] > feature['properties']['section'][1]:\n",
    "                        feature['properties']['section'][0] = 0\n",
    "                        feature['properties']['section'][1] = 0\n",
    "\n",
    "                    if  feature['properties']['referenceId'] is None:\n",
    "                        null_matched.append(str(feature['properties']['{}'.format(primary_key1)]))\n",
    "                        continue\n",
    "\n",
    "                    row = (feature['properties']['referenceId'], \n",
    "                               feature['properties']['fromIntersectionId'],\n",
    "                               feature['properties']['toIntersectionId'],\n",
    "                               feature['properties']['roadClass'], \n",
    "                               feature['properties']['direction'],\n",
    "                               feature['properties']['referenceLength'],\n",
    "                               feature['properties']['side'], \n",
    "                               feature['properties'].get('score', None),\n",
    "                               '[' + str(feature['properties']['section'][0]) +', '+ str(feature['properties']['section'][1]) +')', \n",
    "                               'SRID=4326;LineString('+','.join(' '.join(str(x) for x in tup) for tup in feature['geometry']['coordinates'])+')', \n",
    "                               feature['properties']['originalFeature']['properties']['{}'.format(primary_key1)],\n",
    "                               None)\n",
    "\n",
    "\n",
    "                    rows.append(row)\n",
    "\n",
    "\n",
    "\n",
    "                    sql='INSERT INTO {} (reference_id, from_intersection, to_intersection, road_class, direction, reference_length, side,score, section, geometry, {},  query_num) VALUES %s'.format(output_table,primary_key1)\n",
    "\n",
    "\n",
    "                    with con:\n",
    "                        with con.cursor() as cur:\n",
    "                            execute_values(cur, \n",
    "                                       sql, \n",
    "                                       rows) \n",
    "    \n",
    "    \n",
    "    # put info on query into appropriate table\n",
    "    sql_query_info = 'INSERT INTO {} (bearing_tolerance, search_radius, length_tolerance, total_rows, matched_rows)  VALUES %s'.format(bearing_tolerance, search_radius,\n",
    "                                                                                                                length_tolerance,len(unmatched_rows),count-len(unmatched_rows))\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql_query_info) \n",
    "            \n",
    "            \n",
    "    # get query_num from query info table (i.e. the serial value that was just inputted)\n",
    "    sql_get_query_num = \"SELECT GREATEST(query_num) AS query_num FROM {}\".format(query_info_table)\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            query_num = cur.execute(sql_get_query_num) \n",
    "            query_results = cur.fetchall()\n",
    "            query_num = count_results[0]['query_num']\n",
    "    \n",
    "    \n",
    "    # update the output table with the correct query number so we can link the output table to the query_num table \n",
    "    sql_update_with_query_num = 'UPDATE {} set query_num = {} WHERE query_num IS NULL'.format(output_table, query_num)\n",
    "    \n",
    "    with con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql_update_with_query_num) \n",
    "\n",
    "    \n",
    "\n",
    "    return unmatched_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterhub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
